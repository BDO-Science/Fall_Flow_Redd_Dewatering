allflows <- rbind(kwkFlowData, kesFlowData) #bind gages together
allflows <- allflows %>% #minor cleaning for date and column names
mutate(Date = as.Date(paste0(mm.dd,'-',year), format = '%m-%d-%Y')) %>%
rename('Flow' = 'value') %>% select(Date, Gage = location, Flow)
# Converting flows to Thousand Acre Feet and overlaying real time flows over flow scenarios as season progresses
kes <- allflows %>% filter(Gage =='KES') %>% select(-Gage, Date, KES = 'Flow')
names <- colnames(kesFlow)
names <- names[names != "date"]
kesTemp <- data.frame(Date = kes$Date)
for(i in names) {
name <- i
temp <- data.frame(name = kes$KES)
kesTemp <- cbind(kesTemp, temp)
}
colnames(kesTemp) <- colnames(kesFlow)
kesFlowTemp <- bind_rows(kesTemp, filter(kesFlow, date > max(kes$Date)))
kesFlowTemp <- kesFlowTemp %>%
rename_with(~ paste0(., "_cfs"), -date) %>%  # Rename original columns with '_cfs'
mutate(across(ends_with("_cfs"), ~ . * 1.983 / 1000, .names = "{.col %>% str_replace('_cfs$', '')}_taf"))
septTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "September")
octTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "October")
View(kesFlowTemp)
View(kesFlowReal3)
View(kesFlowReal2)
#loading libraries and pulling in relevant data from excel files
library(tinytex)
library(data.table)
library(plyr)
library(ggplot2)
library(tidyverse)
library(readxl)
library(zoo)
library(kableExtra)
library(janitor)
library(lubridate)
#this function will convert the character values (from xlsx format of numbers with commas) to numeric class values
setClass("num.with.commas")
setAs("character", "num.with.commas",
function(from) as.numeric(gsub(",", "", from) ) )
#setting yr for automating certain lables and filtering
yr = year(Sys.Date())
flow_date <- Sys.Date() #for later filterning
yr_exp <- 2 #this year's expected expansion number based on the linear relationship between yearly expansions vs recapture rate of tagged female salmon
########Read in redd data from shallow winter redd monitoring
redd_files <- list.files('External_data/ShallowRedds/', pattern = "\\.xlsx$", full.names = TRUE) #list all excel files
MaxReddFile <- max(redd_files) #reads the latest redd excel file
reddsheets <- excel_sheets(MaxReddFile) #list all sheets
reddsheet <- reddsheets[reddsheets == 'SHALLOW REDDS'] #filter sheet with shallow redd nfo
redds <- read_excel(MaxReddFile,  sheet = reddsheet, #read in shallow redd file and clean up.
range = cell_cols(c('A:I'))) %>%
na.omit() %>%
select(3,4,6,9) %>%
rename('Born.on.Date' = 1, 'Estimated.Date.of.Emergence' = 2, 'ACTUAL.or.ESTIMATED..DEWATER.FLOW' = 4) %>%
mutate_at(1:2, as.Date)#minor cleaning
reddsAll <- redds #putting in a spare dataframe or later use
########Read in most recent flow scenario data, cleaning up datasheet, etc.
Files <- list.files('External_data/FlowScen/', pattern = "xlsx$")
MaxFile <- max(Files)
flowsheets <- excel_sheets(paste0('External_data/FlowScen/',MaxFile))
flowsheet <- grep("Alternatives", flowsheets, value = TRUE) #for pulling in flow alternatives
scensheet <- grep("Desired", flowsheets, value = TRUE) #for pulling in desired scenarios sheet
#pull in desired scenarios
scen <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = scensheet, col_names = TRUE) %>%
filter(Use == 'Y') %>%
clean_names() %>%
mutate(scenario = gsub("[^[:alnum:]]+", "", scenario)) %>%
mutate(scenario = tolower(scenario)) %>%
pull(scenario)
#pull in flow alternatives
kesFlowTemp <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
mutate(Date = as.Date(as.numeric(Date), origin = "1899-12-30")) %>%
filter(!is.na(Date)) %>%
select(-contains("Actual"), -contains("Timeline")) %>%  # Exclude columns with 'Actual' and 'Timeline'
select_if(~ !all(is.na(.))) %>% #Exlcude blank columns
gather(key = scenarios, value = flow, -Date) %>% #gather for easier filtering
clean_names() %>%
mutate(scenarios = gsub("[^[:alnum:]]+", "", scenarios)) %>%
mutate(scenarios = tolower(scenarios))
kesFlow <- kesFlowTemp %>%
filter(scenarios %in% scen) %>% #filter for desired scenarios
spread(key = scenarios, value = flow) #spread back out for later use
########Import relevant fall-run redd dewatering data
#import fall-run spawn info
spawn <- read.csv('Model_inputs/spawn_timing.csv') %>%
mutate(Date = as.Date(Day, origin = as.Date(paste0(yr,'-01-01')))) %>% #converts Julian Day to date for current year
rename('EmergDays' = 'EmergDate') %>% #renaming for later use
filter(Run == 'Fall') #filtering just for fall-run
#import gard look up table
fall_lookup <- read.csv('Model_inputs/model_dewater_flows.csv') %>%
rename('GardDewater' = 'Dewater', 'GardSpawn' = 'Spawn_Flows') %>%
filter(Run == 'Fall')
########read in Redd Count data and date from most recent file with that info (different folder than standard redd files)
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files('External_data/ShallowRedds/ReddCount/',
pattern = "xlsx$") #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE)) %>%
pull(name)
#for Count data
Count <- read_excel(paste0('External_data/ShallowRedds/ReddCount/',MaxCountFile),
sheet = sheetCount) #pull in sheet with count data
reddCount <- round(as.numeric(Count[[(which(Count[, 2] == 'To date, unexpanded redd count') + 1), 2]]),0) #isolate count
countDate <- format(as.Date(as.numeric(Count[[(which(Count[, 1] == 'Through') + 1), 1]]),
origin = "1899-12-30"), "%B %d, %Y") #isolate count data
updatedReddInfoDate <- format(as.Date(gsub(".*?(\\d{4}-\\d{2}-\\d{2}).*", "\\1", MaxReddFile), format = "%Y-%m-%d"), "%B %d, %Y") #isolate most recent redd info date from file name
View(kesFlow)
kesAug90 <- kesFlowTemp %>% filter(scenerios == 'aug90')
kesAug90 <- kesFlowTemp %>% filter(scenarios == 'aug90')
View(kesAug90)
View(allflows)
kesAug90 <- kesFlowTemp %>% filter(scenarios == 'aug90' & date > allflows$Date)
kesAug90 <- kesFlowTemp %>% filter(scenarios == 'aug90' & date > max(allflows$Date))
kesAug90 <- kesFlowTemp %>%
filter(scenarios == 'aug90' & date > max(allflows$Date)) %>%
select(1,3)
bind_row(select(filter(allflows, Gage == 'KES'), 'date' = 1, 'flow' = 3))
kesAug90 <- kesFlowTemp %>%
filter(scenarios == 'aug90' & date > max(allflows$Date)) %>%
select(1,3)
bind_rows(select(filter(allflows, Gage == 'KES'), 'date' = 1, 'flow' = 3))
kesAug90 <- kesFlowTemp %>%
filter(scenarios == 'aug90' & date > max(allflows$Date)) %>%
select(1,3) %>%
bind_rows(select(filter(allflows, Gage == 'KES'), 'date' = 1, 'flow' = 3))
kesAug90 <- kesFlowTemp %>%
filter(scenarios == 'aug90' & date > max(allflows$Date)) %>%
select(1,3) %>%
bind_rows(select(filter(allflows, Gage == 'KES'), 'date' = 1, 'flow' = 3)) %>%
arrange(date)
eos_aug90 <- kesAug90 %>% filter(date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01')) %>% pull(sum(flow))
eos_aug90 <- kesAug90 %>% filter(date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))
View(eos_aug90)
eos_aug90 <- colSums(filter(date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01')))[,-1]*1.983/1000
eos_aug90 <- colSums(filter(kesAug90, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01')))[,-1]*1.983/1000
filtered_data <- filter(kesAug90, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))
eos_aug90 <- colSums(filtered_data[, -1]) * 1.983 / 1000
#do any EOS fall below 2200 TAF?
EOS <- 2717
eosList <- list()
eosList <- eosList %>% append(
list(total_volume_as = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
filtered_data <- filter(kesAug90, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))
eos_aug90 <- colSums(filtered_data[, -1]) * 1.983 / 1000
eosList <- eosList %>% append(
list(Difference_from_aug90 = (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
eosList <- eosList %>% append(
list(Resulting_EOS = (EOS - (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000))),
after = length(eosList)
)
if(min(eosList$Resulting_EOS) > 2200){
TDM <- "All proposed scenarios are anticipated to have EOS storage greater than the 2200 TAF threshold and therefore would not be expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
} else {
TDM <- "One or more proposed scenarios are anticipated to have EOS storage below the 2200 TAF threshold and therefore would be expected to contribute to TDM in the subsequent year, though scenarios above the threshold are not expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
}
#loading libraries and pulling in relevant data from excel files
library(tinytex)
library(data.table)
library(plyr)
library(ggplot2)
library(tidyverse)
library(readxl)
library(zoo)
library(kableExtra)
library(janitor)
library(lubridate)
#this function will convert the character values (from xlsx format of numbers with commas) to numeric class values
setClass("num.with.commas")
setAs("character", "num.with.commas",
function(from) as.numeric(gsub(",", "", from) ) )
#setting yr for automating certain lables and filtering
yr = year(Sys.Date())
flow_date <- Sys.Date() #for later filterning
yr_exp <- 2 #this year's expected expansion number based on the linear relationship between yearly expansions vs recapture rate of tagged female salmon
########Read in redd data from shallow winter redd monitoring
redd_files <- list.files('External_data/ShallowRedds/', pattern = "\\.xlsx$", full.names = TRUE) #list all excel files
MaxReddFile <- max(redd_files) #reads the latest redd excel file
reddsheets <- excel_sheets(MaxReddFile) #list all sheets
reddsheet <- reddsheets[reddsheets == 'SHALLOW REDDS'] #filter sheet with shallow redd nfo
redds <- read_excel(MaxReddFile,  sheet = reddsheet, #read in shallow redd file and clean up.
range = cell_cols(c('A:I'))) %>%
na.omit() %>%
select(3,4,6,9) %>%
rename('Born.on.Date' = 1, 'Estimated.Date.of.Emergence' = 2, 'ACTUAL.or.ESTIMATED..DEWATER.FLOW' = 4) %>%
mutate_at(1:2, as.Date)#minor cleaning
reddsAll <- redds #putting in a spare dataframe or later use
########Read in most recent flow scenario data, cleaning up datasheet, etc.
Files <- list.files('External_data/FlowScen/', pattern = "xlsx$")
MaxFile <- max(Files)
flowsheets <- excel_sheets(paste0('External_data/FlowScen/',MaxFile))
flowsheet <- grep("Alternatives", flowsheets, value = TRUE) #for pulling in flow alternatives
scensheet <- grep("Desired", flowsheets, value = TRUE) #for pulling in desired scenarios sheet
#pull in desired scenarios
scen <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = scensheet, col_names = TRUE) %>%
filter(Use == 'Y') %>%
clean_names() %>%
mutate(scenario = gsub("[^[:alnum:]]+", "", scenario)) %>%
mutate(scenario = tolower(scenario)) %>%
pull(scenario)
#pull in flow alternatives
kesFlowTemp <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
mutate(Date = as.Date(as.numeric(Date), origin = "1899-12-30")) %>%
filter(!is.na(Date)) %>%
select(-contains("Actual"), -contains("Timeline")) %>%  # Exclude columns with 'Actual' and 'Timeline'
select_if(~ !all(is.na(.))) %>% #Exlcude blank columns
gather(key = scenarios, value = flow, -Date) %>% #gather for easier filtering
clean_names() %>%
mutate(scenarios = gsub("[^[:alnum:]]+", "", scenarios)) %>%
mutate(scenarios = tolower(scenarios))
kesFlow <- kesFlowTemp %>%
filter(scenarios %in% scen) %>% #filter for desired scenarios
spread(key = scenarios, value = flow) #spread back out for later use
########Import relevant fall-run redd dewatering data
#import fall-run spawn info
spawn <- read.csv('Model_inputs/spawn_timing.csv') %>%
mutate(Date = as.Date(Day, origin = as.Date(paste0(yr,'-01-01')))) %>% #converts Julian Day to date for current year
rename('EmergDays' = 'EmergDate') %>% #renaming for later use
filter(Run == 'Fall') #filtering just for fall-run
#import gard look up table
fall_lookup <- read.csv('Model_inputs/model_dewater_flows.csv') %>%
rename('GardDewater' = 'Dewater', 'GardSpawn' = 'Spawn_Flows') %>%
filter(Run == 'Fall')
########read in Redd Count data and date from most recent file with that info (different folder than standard redd files)
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files('External_data/ShallowRedds/ReddCount/',
pattern = "xlsx$") #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE)) %>%
pull(name)
#for Count data
Count <- read_excel(paste0('External_data/ShallowRedds/ReddCount/',MaxCountFile),
sheet = sheetCount) #pull in sheet with count data
reddCount <- round(as.numeric(Count[[(which(Count[, 2] == 'To date, unexpanded redd count') + 1), 2]]),0) #isolate count
countDate <- format(as.Date(as.numeric(Count[[(which(Count[, 1] == 'Through') + 1), 1]]),
origin = "1899-12-30"), "%B %d, %Y") #isolate count data
updatedReddInfoDate <- format(as.Date(gsub(".*?(\\d{4}-\\d{2}-\\d{2}).*", "\\1", MaxReddFile), format = "%Y-%m-%d"), "%B %d, %Y") #isolate most recent redd info date from file name
View(kesFlow)
#####pulling in real-time flow data for KES and KWK
# query parameters for SacPAS
# calendar year
queryYear=yr
# query dates can be empty string "" or explicit "mm/dd" (value will be NA for future dates or missing dates)
# empty string for end date will result in data through most recent date in database for given year
querySD="8/1"
queryED= paste0(month(Sys.Date()),'/',day(Sys.Date()-1))
outputFormat="csvSingle"
# KWK river flow data from SacPAS
queryKWKflow=paste("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?mgconfig=river&loc[]=KWK&data[]=Flow&outputFormat=",outputFormat,"&year[]=",queryYear,"&startdate=",querySD,"&enddate=",queryED, sep="")
kwkFlowData = read.csv(queryKWKflow) %>% slice(1:(n()-3))
# KES reservoir flow data from SacPAS
queryKESflow=paste("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?mgconfig=river&loc[]=KES&data[]=ReservoirOutflow&outputFormat=",outputFormat,"&year[]=",queryYear,"&startdate=",querySD,"&enddate=",queryED, sep="")
kesFlowData = read.csv(queryKESflow) %>% slice(1:(n()-3))
allflows <- rbind(kwkFlowData, kesFlowData) #bind gages together
allflows <- allflows %>% #minor cleaning for date and column names
mutate(Date = as.Date(paste0(mm.dd,'-',year), format = '%m-%d-%Y')) %>%
rename('Flow' = 'value') %>% select(Date, Gage = location, Flow)
# Converting flows to Thousand Acre Feet and overlaying real time flows over flow scenarios as season progresses
kes <- allflows %>% filter(Gage =='KES') %>% select(-Gage, Date, KES = 'Flow')
names <- colnames(kesFlow)
names <- names[names != "date"]
kesTemp <- data.frame(Date = kes$Date)
for(i in names) {
name <- i
temp <- data.frame(name = kes$KES)
kesTemp <- cbind(kesTemp, temp)
}
colnames(kesTemp) <- colnames(kesFlow)
kesFlowReal <- bind_rows(kesTemp, filter(kesFlow, date > max(kes$Date)))
kesFlowReal <- kesFlowReal %>%
rename_with(~ paste0(., "_cfs"), -date) %>%  # Rename original columns with '_cfs'
mutate(across(ends_with("_cfs"), ~ . * 1.983 / 1000, .names = "{.col %>% str_replace('_cfs$', '')}_taf"))
#Pulling out Aug 90 forecast flow for comparison purposes.  Might need to delete later.
kesAug90 <- kesFlowTemp %>%
filter(scenarios == 'aug90' & date > max(allflows$Date)) %>%
select(1,3) %>%
bind_rows(select(filter(allflows, Gage == 'KES'), 'date' = 1, 'flow' = 3)) %>%
arrange(date)
septTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "September")
octTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "October")
# September Flow Average
septKesFlow <- subset (kesFlowReal, kesFlowReal$date < paste0(yr,'-10-01') & kesFlowReal$date >= paste0(yr, '-9-01'))
septKesFlow <- septKesFlow %>% select(date, contains("_cfs"))
octKesFlow <- subset (kesFlowReal, kesFlowReal$date >= paste0(yr,'-10-01') & kesFlowReal$date < paste0(yr, '-11-01'))
octKesFlow <- octKesFlow %>% select(date, contains("_cfs"))
View(septKesFlow)
#estimate fall-run redds dewatered
#function for converting flows to nearest number in Gard lookup
round_to_nearest <- function(x, basis_vector) {
nearest_value <- basis_vector[which.min(abs(basis_vector - x))]
return(nearest_value)
}
#transform kesFlowReal dataframe for model
redd_model <- kesFlowReal %>%
gather(key = Scenarios, value = Spawn_Flows, contains('cfs')) %>%
select(date, Scenarios, Spawn_Flows) %>%
mutate(Boards = if_else(date < as.Date(paste0(yr,'-11-01')), 'in', 'out')) %>%
mutate(Spawn_Flows = as.numeric(Spawn_Flows)) %>%
left_join(spawn, by = c('date'= 'Date')) %>%
filter(!is.na(Run)) %>%
mutate(Spawn_Flows = na.approx(Spawn_Flows), EmergDate = date + EmergDays) %>%
mutate(Dewater = sapply(EmergDate, function(edate) {
if (!is.na(edate)) {
min(Spawn_Flows[date <= edate & date >= date], na.rm = TRUE)
} else {
NA
}
})) %>%
mutate(Boards = if_else(month(date) < 11, 'in', 'out'))
#rounding spawning flows and dewatering flows (minimum flows) to nearest flow value in Gard Lookup
redd_model <- redd_model %>%
mutate(GardSpawn = sapply(redd_model$Spawn_Flows, round_to_nearest, fall_lookup$GardSpawn)) %>%
mutate(GardDewater = sapply(redd_model$Dewater, round_to_nearest, fall_lookup$GardDewater)) %>%
left_join(fall_lookup, by = c('GardDewater', 'GardSpawn', 'Boards')) %>%
mutate(Prop_dewater = if_else(is.na(Prop_dewater), 0, Prop_dewater)) %>%
mutate(TotalDewater = Prop * Prop_dewater) #multiplying proportion dewatered by the proportion spawning
summary <- redd_model %>% group_by(Scenarios) %>% #summarize total dewatering by Scenario
summarize(Redds_lost = round((sum(TotalDewater)*100), 1)) %>%
rename('Fall-run dewatered (%)' = 'Redds_lost')
#manipulating summary table for later binding to another summary table.
table2 <- setDT(as.data.frame(t(summary)), keep.rownames = TRUE, check.names = TRUE)
names(table2) <- table2 %>% slice(1) %>% unlist()
table2 <- table2 %>%
slice(-1) %>%
rename('Metric' = 1)
# create a table for population expansions
pop_tab <- data.frame(Name = c("Current Count", "Anticipated Expansion"),
Expansion = c(1,2)
)
pop_tab <- pop_tab %>%
mutate(Redds = round(reddCount*Expansion, 0),
"1%" = Redds*0.01) %>%
rename("Expansion Number" = Expansion,
"Total Redds" = Redds)
if (knitr::is_html_output()) {
knitr::kable(pop_tab,
caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
} else if (knitr::is_latex_output()) {
knitr::kable(pop_tab,
caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(pop_tab) %>%
flextable::set_caption(caption = 'Table 1. Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.') %>%
flextable::width(width = 1.5, unit = "in") %>%
flextable::font(font = 'Cambria', part = 'all')
}
library(lubridate)
# Estimated number of redds dewatered
kesFlowReal2 <- kesFlowReal %>% select(date, contains("_cfs"))
kesFlowReal3 <- kesFlowReal2 %>% gather(key = 'Alts', value = 'Flow', -date)
name2 <- colnames(kesFlowReal2)
name2 <- name2[name2 != "date"]
#formatting new redds file for figuring out minimum flows
redds2 <- subset(redds, redds$Status == "OK" | redds$Status == "DEWATERED")
for (col in name2) { #adding alternative names to redd dataframe
redds2[[col]] <- NA
}
redds2 <- redds2 %>% gather(key = 'Alts', value = 'Flow', -1:-4) %>%
select(-Flow)
flowList <- list()
for(i in 1:nrow(redds2)){
filtered <- kesFlowReal3 %>% filter(Alts == redds2$Alts[i]) %>%
filter(date >= redds2$Born.on.Date[i] & date <= redds2$Estimated.Date.of.Emergence[i])
minflow <- min(filtered$Flow)
flowList[[i]] <- minflow
}
tempRedds <- cbind(flowList)
dewater <- cbind(redds2, tempRedds)
dewater <- dewater %>% mutate(Dewater = if_else(flowList <= ACTUAL.or.ESTIMATED..DEWATER.FLOW, 1, 0)) %>%
mutate(Dewater_Buffer = ACTUAL.or.ESTIMATED..DEWATER.FLOW + 250) %>%
mutate(Dewatered_Buffer = if_else(flowList <= Dewater_Buffer, 1, 0)) %>%
gather(key = 'Type', value = 'Dewater', 7,9) %>%
mutate(Buffer = if_else(grepl('Buffer', Type), 'YES', 'NO')) %>%
select(5,9,10) %>%
mutate(key = row_number())
dewater <- dewater %>% spread(key = 'Alts', value = 'Dewater')
#do any EOS fall below 2200 TAF?
EOS <- 2717
eosList <- list()
eosList <- eosList %>% append(
list(total_volume_as = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
filtered_data <- filter(kesAug90, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))
eos_aug90 <- colSums(filtered_data[, -1]) * 1.983 / 1000
eosList <- eosList %>% append(
list(Difference_from_aug90 = (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
eosList <- eosList %>% append(
list(Resulting_EOS = (EOS - (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000))),
after = length(eosList)
)
if(min(eosList$Resulting_EOS) > 2200){
TDM <- "All proposed scenarios are anticipated to have EOS storage greater than the 2200 TAF threshold and therefore would not be expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
} else {
TDM <- "One or more proposed scenarios are anticipated to have EOS storage below the 2200 TAF threshold and therefore would be expected to contribute to TDM in the subsequent year, though scenarios above the threshold are not expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
}
#automating expansion row names for table
exp <- vector()
pop_temp <- pop_tab %>% rename('Expansion' = 'Expansion Number') %>% filter(Expansion > 1, !grepl('Expected', Name))
for(i in 1:nrow(pop_temp)){
temp <- pop_temp[i,'Expansion']
temp <- paste0('Winter-run Percent Lost (expansion of ', temp,')')
exp[i] <- temp
}
#creating row names for table
Metric <- c("Avg Sept Flow (cfs)", "Avg Oct Flow (cfs)", "Sept-Feb Total Volume (TAF)", "Aug-Sept Total Volume (TAF)", "Anticipated EOS Storage (TAF)", "Winter-run Redds Dewatered", "Winter-run Percent Lost (current count)", "Winter-run Percent Lost (mean expansion of 2)", "Winter-run Redds Dewatered (250 cfs buffer)", "Winter-run Percent Lost (250 cfs buffer)")
#creating the table using the row names
table <- data.frame(Metric)
#creating a list to store all summary statistics below
tableList <- list()
#summary statistics for flow which are stored in tableList
tableList <- append(tableList, list(avg_sept_flow = colMeans(septKesFlow[,-1], na.rm = TRUE)), after = length(tableList))
tableList <- append(tableList, list(avg_oct_flow = colMeans(octKesFlow[,-1], na.rm = TRUE)), after = length(tableList))
tableList <- tableList %>% append(
list(total_volume_sf = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-09-01') & date < paste0(yr+1,'-03-01'))[, -1])*1.983/1000)),
after = length(tableList)
)
tableList <- tableList %>% append(
list(total_volume_as = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(tableList)
)
tableList <- tableList %>% append(
list(Resulting_EOS = (EOS - (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000))),
after = length(tableList)
)
#summary statistics for redd dewatering
tableList <- tableList %>% append(
list(wr_dewatered = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE))),
after = length(tableList)
)
tableList <- tableList %>% append(
list(wr_pct_lost = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE)/reddCount)*100),
after = length(tableList)
)
#summary statistics for redd dewatering with expansion factors
tableList <- tableList %>% append(
list(wr_pct_lost_300 = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE)/(reddCount*2))*100),
after = length(tableList)
)
#summary statsitics for redd dewatering with flow buffer
tableList <- tableList %>% append(
list(wr_dewatered_250 = (colSums(filter(dewater, Buffer == 'YES')[, -1:-2], na.rm = TRUE))),
after = length(tableList)
)
tableList <- tableList %>% append(
list(wr_pct_lost_250 = (colSums(filter(dewater, Buffer == 'YES')[, -1:-2], na.rm = TRUE)/reddCount)*100),
after = length(tableList)
)
#binding summary statistics into one table
temp_table <- bind_rows(tableList)
#binding to original table with row names
table <- bind_cols(Metric, temp_table) %>% rename('Metric' = 1)
#adding fall-run dewatering to table
table <- rbind(table, setNames(table2, names(table))) %>%
mutate_at(c(2:ncol(table)), as.numeric)
# Separate the data into two parts: the first 5 rows and the remaining rows
table[,2:ncol(table)] <- round(table[,2:ncol(table)], 2)
# Print the modified table
colnames(table) <- gsub("_cfs$", "", colnames(table))
table_rounded <- table %>%
mutate(across(-Metric,
~ ifelse(row_number() <= 6,
format(round(.x, digits = 0), nsmall = 0, trim = TRUE),
round(.x, digits = 2))))
#knitr::kable(table,
#caption = paste0('Summary of various factors related to flow scenarios. Each scenario uses actual flow-to-date as of most current report and proposed flows for the remainder of the incubation period. Percentage of the population lost is based on the ',countDate,' count of ',reddCount,' Winter-run redds and updated redd counts may be available soon. See Scenario Descriptions file for additional information on each scenario.')) %>%
# kable_styling(font_size = 8) %>%
#column_spec(1, width = "4cm")
# Dynamically render table based on output format
if (knitr::is_html_output()) {
knitr::kable(table_rounded,
caption = paste0('Summary of water volume and winter-run and fall-run dewatering estimates related to flow scenarios. Each scenario uses actual flow-to-date as of most current report and proposed flows for the remainder of the incubation period. Percentage of the population lost is based on the ', countDate, ' count of ', reddCount, ' Winter-run redds. See Scenario Descriptions file for additional information on each scenario.')
)
} else if (knitr::is_latex_output()) {
knitr::kable(table_rounded,
caption = paste0('Summary of water volume and winter-run and fall-run dewatering estimates related to flow scenarios. Each scenario uses actual flow-to-date as of most current report and proposed flows for the remainder of the incubation period. Percentage of the population lost is based on the ', countDate, ' count of ', reddCount, ' Winter-run redds. See Scenario Descriptions file for additional information on each scenario.')
) %>%
kable_styling(font_size = 8) %>%
column_spec(1, width = "4cm")
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(table_rounded) %>%
flextable::set_caption(caption = paste0('Table 2. Summary of water volume and winter-run and fall-run dewatering estimates related to flow scenarios. Each scenario uses actual flow-to-date as of most current report and proposed flows for the remainder of the incubation period. Percentage of the population lost is based on the ', countDate, ' count of ', reddCount, ' Winter-run redds. See Scenario Descriptions file for additional information on each scenario.')) %>%
flextable::width(width = 1, unit = "in") %>%
flextable::align(j = -1, align = 'center', part = 'all') %>%
flextable::font(font = 'Cambria', part = 'all')
}
View(allflows)
View(kesFlowReal)
View(kesTemp)
View(kesFlow)
View(kes)
View(allflows)
View(kwkFlowData)
queryED= Sys.Date()-1
queryED=Sys.Date()-1
queryED= paste0(month(queryED),'/',day(queryED))
