caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
} else if (knitr::is_latex_output()) {
knitr::kable(pop_tab,
caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.') %>%
kable_styling(font_size = 8)
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(pop_tab) %>%
flextable::set_caption(caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
}
#loading libraries and pulling in relevant data from excel files
library(tinytex)
library(data.table)
library(plyr)
library(ggplot2)
library(tidyverse)
library(readxl)
library(zoo)
library(kableExtra)
library(janitor)
library(lubridate)
#set desired scenarios for later filtering
#scenarios <- c("Alt.1c", "Alt.2e", "Alt.3m", "Alt.3r", "Alt.3s")
#this function will convert the character values (from xlsx format of numbers with commas) to numeric class values
setClass("num.with.commas")
setAs("character", "num.with.commas",
function(from) as.numeric(gsub(",", "", from) ) )
#setting yr for automating certain lables and filtering
yr = year(Sys.Date())
flow_date <- Sys.Date() #for later filterning
yr_exp <- 2 #this year's expected expansion number based on the linear relationship between yearly expansions vs recapture rate of tagged female salmon
########Read in redd data from shallow winter redd monitoring
redd_files <- list.files('External_data/ShallowRedds/', pattern = "\\.xlsx$", full.names = TRUE) #list all excel files
MaxReddFile <- max(redd_files) #reads the latest redd excel file
reddsheets <- excel_sheets(MaxReddFile) #list all sheets
reddsheet <- reddsheets[reddsheets == 'SHALLOW REDDS'] #filter sheet with shallow redd nfo
redds <- read_excel(MaxReddFile,  sheet = reddsheet, #read in shallow redd file and clean up.
range = cell_cols(c('A:I'))) %>%
na.omit() %>%
select(3,4,6,9) %>%
rename('Born.on.Date' = 1, 'Estimated.Date.of.Emergence' = 2, 'ACTUAL.or.ESTIMATED..DEWATER.FLOW' = 4) %>%
mutate_at(1:2, as.Date)#minor cleaning
reddsAll <- redds
########Read in most recent flow scenario data, cleaning up datasheet, etc.
Files <- list.files('External_data/FlowScen/', pattern = "xlsx$")
MaxFile <- max(Files)
flowsheets <- excel_sheets(paste0('External_data/FlowScen/',MaxFile))
flowsheet <- grep("Alternatives", flowsheets, value = TRUE) #for pulling in flow alternatives
scensheet <- grep("Desired", flowsheets, value = TRUE) #for pulling in desired scenarios sheet
#pull in desired scenarios
scen <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = scensheet, col_names = TRUE) %>%
filter(Use == 'Y') %>%
clean_names() %>%
mutate(scenario = gsub("[^[:alnum:]]+", "", scenario)) %>%
mutate(scenario = tolower(scenario)) %>%
pull(scenario)
#pull in flow alternatives
kesFlow <- read_excel(paste0('External_data/FlowScen/',MaxFile),
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
mutate(Date = as.Date(as.numeric(Date), origin = "1899-12-30")) %>%
filter(!is.na(Date)) %>%
select(-contains("Actual"), -contains("Timeline")) %>%  # Exclude columns with 'Actual' and 'Timeline'
select_if(~ !all(is.na(.))) %>% #Exlcude blank columns
gather(key = scenarios, value = flow, -Date) %>% #gather for easier filtering
clean_names() %>%
mutate(scenarios = gsub("[^[:alnum:]]+", "", scenarios)) %>%
mutate(scenarios = tolower(scenarios)) %>%
filter(scenarios %in% scen) %>% #filter for desired scenarios
spread(key = scenarios, value = flow) #spread back out for later use
########Import relevant fall-run redd dewatering data
#import fall-run spawn info
spawn <- read.csv('Model_inputs/spawn_timing.csv') %>%
mutate(Date = as.Date(Day, origin = as.Date(paste0(yr,'-01-01')))) %>% #converts Julian Day to date for current year
rename('EmergDays' = 'EmergDate') %>% #renaming for later use
filter(Run == 'Fall') #filtering just for fall-run
#import gard look up table
fall_lookup <- read.csv('Model_inputs/model_dewater_flows.csv') %>%
rename('GardDewater' = 'Dewater', 'GardSpawn' = 'Spawn_Flows') %>%
filter(Run == 'Fall')
########read in Redd Count data and date from most recent file
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files('External_data/ShallowRedds/ReddCount/',
pattern = "xlsx$") #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE)) #lists all excel sheets in the file
#for Count data
Count <- read_excel(paste0('External_data/ShallowRedds/ReddCount/',MaxCountFile),
sheet = sheetCount[1,1]) #pull in sheet with count data
reddCount <- round(as.numeric(Count[[(which(Count[, 2] == 'To date, unexpanded redd count') + 1), 2]]),0) #isolate count
countDate <- format(as.Date(as.numeric(Count[[(which(Count[, 1] == 'Through') + 1), 1]]),
origin = "1899-12-30"), "%B %d, %Y") #isolate count data
updatedReddInfoDate <- format(as.Date(gsub(".*?(\\d{4}-\\d{2}-\\d{2}).*", "\\1", MaxReddFile), format = "%Y-%m-%d"), "%B %d, %Y") #isolate most recent redd info date from file name
#####pulling in real-time flow data for KES and KWK
# query parameters for SacPAS
# calendar year
queryYear=yr
# query dates can be empty string "" or explicit "mm/dd" (value will be NA for future dates or missing dates)
# empty string for end date will result in data through most recent date in database for given year
querySD="8/1"
queryED= paste0(month(Sys.Date()),'/',day(Sys.Date()-1))
outputFormat="csvSingle"
# KWK river flow data from SacPAS
queryKWKflow=paste("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?mgconfig=river&loc[]=KWK&data[]=Flow&outputFormat=",outputFormat,"&year[]=",queryYear,"&startdate=",querySD,"&enddate=",queryED, sep="")
kwkFlowData = read.csv(queryKWKflow) %>% slice(1:(n()-3))
# KES reservoir flow data from SacPAS
queryKESflow=paste("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?mgconfig=river&loc[]=KES&data[]=ReservoirOutflow&outputFormat=",outputFormat,"&year[]=",queryYear,"&startdate=",querySD,"&enddate=",queryED, sep="")
kesFlowData = read.csv(queryKESflow) %>% slice(1:(n()-3))
allflows <- rbind(kwkFlowData, kesFlowData)
allflows <- allflows %>%
mutate(Date = as.Date(paste0(mm.dd,'-',year), format = '%m-%d-%Y')) %>%
rename('Flow' = 'value') %>% select(Date, Gage = location, Flow)
# Converting flows to Thousand Acre Feet and overlaying real time flows over flow scenarios as season progresses
kes <- allflows %>% filter(Gage =='KES') %>% select(-Gage, Date, KES = 'Flow')
names <- colnames(kesFlow)
names <- names[names != "date"]
kesTemp <- data.frame(Date = kes$Date)
for(i in names) {
name <- i
temp <- data.frame(name = kes$KES)
kesTemp <- cbind(kesTemp, temp)
}
colnames(kesTemp) <- colnames(kesFlow)
kesFlowReal <- bind_rows(kesTemp, filter(kesFlow, date > max(kes$Date)))
kesFlowReal <- kesFlowReal %>%
rename_with(~ paste0(., "_cfs"), -date) %>%  # Rename original columns with '_cfs'
mutate(across(ends_with("_cfs"), ~ . * 1.983 / 1000, .names = "{.col %>% str_replace('_cfs$', '')}_taf"))
septTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "September")
octTAF <- subset(kesFlowReal, months(kesFlowReal$date) == "October")
# September Flow Average
septKesFlow <- subset (kesFlowReal, kesFlowReal$date < paste0(yr,'-10-01') & kesFlowReal$date >= paste0(yr, '-9-01'))
septKesFlow <- septKesFlow %>% select(date, contains("_cfs"))
octKesFlow <- subset (kesFlowReal, kesFlowReal$date >= paste0(yr,'-10-01') & kesFlowReal$date < paste0(yr, '-11-01'))
octKesFlow <- octKesFlow %>% select(date, contains("_cfs"))
#estimate fall-run redds dewatered
#function for converting flows to nearest number in Gard lookup
round_to_nearest <- function(x, basis_vector) {
nearest_value <- basis_vector[which.min(abs(basis_vector - x))]
return(nearest_value)
}
#transform kesFlowReal dataframe for model
redd_model <- kesFlowReal %>%
gather(key = Scenarios, value = Spawn_Flows, contains('cfs')) %>%
select(date, Scenarios, Spawn_Flows) %>%
mutate(Boards = if_else(date < as.Date(paste0(yr,'-11-01')), 'in', 'out')) %>%
mutate(Spawn_Flows = as.numeric(Spawn_Flows)) %>%
left_join(spawn, by = c('date'= 'Date')) %>%
filter(!is.na(Run)) %>%
mutate(Spawn_Flows = na.approx(Spawn_Flows), EmergDate = date + EmergDays) %>%
mutate(Dewater = sapply(EmergDate, function(edate) {
if (!is.na(edate)) {
min(Spawn_Flows[date <= edate & date >= date], na.rm = TRUE)
} else {
NA
}
})) %>%
mutate(Boards = if_else(month(date) < 11, 'in', 'out'))
redd_model <- redd_model %>%
mutate(GardSpawn = sapply(redd_model$Spawn_Flows, round_to_nearest, fall_lookup$GardSpawn)) %>%
mutate(GardDewater = sapply(redd_model$Dewater, round_to_nearest, fall_lookup$GardDewater)) %>%
left_join(fall_lookup, by = c('GardDewater', 'GardSpawn', 'Boards')) %>%
mutate(Prop_dewater = if_else(is.na(Prop_dewater), 0, Prop_dewater)) %>%
mutate(TotalDewater = Prop * Prop_dewater)
summary <- redd_model %>% group_by(Scenarios) %>%
summarize(Redds_lost = round((sum(TotalDewater)*100), 1)) %>%
rename('Fall-run dewatered (%)' = 'Redds_lost')
table2 <- setDT(as.data.frame(t(summary)), keep.rownames = TRUE, check.names = TRUE)
names(table2) <- table2 %>% slice(1) %>% unlist()
table2 <- table2 %>%
slice(-1) %>%
rename('Metric' = 1)
# create a table for population expansions
pop_tab <- data.frame(Name = c("Current Count", "Anticipated Expansion"),
Expansion = c(1,2)
)
pop_tab <- pop_tab %>%
mutate(Redds = round(reddCount*Expansion, 0),
"1%" = Redds*0.01) %>%
rename("Expansion Number" = Expansion,
"Total Redds" = Redds)
if (knitr::is_html_output()) {
knitr::kable(pop_tab,
caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
} else if (knitr::is_latex_output()) {
knitr::kable(pop_tab,
caption = 'Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.')
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(pop_tab) %>%
flextable::set_caption(caption = 'Table 1. Estimated total number of Winter-run redds and resulting number of redds that represent 1% of the population. Estimated total redds are based on current count and expansion number representing average 2005-2022 expansion.') %>%
flextable::width(width = 1, unit = "in")
}
library(lubridate)
# Estimated number of redds dewatered
kesFlowReal2 <- kesFlowReal %>% select(date, contains("_cfs"))
kesFlowReal3 <- kesFlowReal2 %>% gather(key = 'Alts', value = 'Flow', -date)
name2 <- colnames(kesFlowReal2)
name2 <- name2[name2 != "date"]
#formatting new redds file for figuring out minimum flows
redds2 <- subset(redds, redds$Status == "OK" | redds$Status == "DEWATERED")
for (col in name2) { #adding alternative names to redd dataframe
redds2[[col]] <- NA
}
redds2 <- redds2 %>% gather(key = 'Alts', value = 'Flow', -1:-4) %>%
select(-Flow)
flowList <- list()
for(i in 1:nrow(redds2)){
filtered <- kesFlowReal3 %>% filter(Alts == redds2$Alts[i]) %>%
filter(date >= redds2$Born.on.Date[i] & date <= redds2$Estimated.Date.of.Emergence[i])
minflow <- min(filtered$Flow)
flowList[[i]] <- minflow
}
test2 <- cbind(flowList)
dewater <- cbind(redds2, test2)
dewater <- dewater %>% mutate(Dewater = if_else(flowList <= ACTUAL.or.ESTIMATED..DEWATER.FLOW, 1, 0)) %>%
mutate(Dewater_Buffer = ACTUAL.or.ESTIMATED..DEWATER.FLOW + 250) %>%
mutate(Dewatered_Buffer = if_else(flowList <= Dewater_Buffer, 1, 0)) %>%
gather(key = 'Type', value = 'Dewater', 7,9) %>%
mutate(Buffer = if_else(grepl('Buffer', Type), 'YES', 'NO')) %>%
select(5,9,10) %>%
mutate(key = row_number())
dewater <- dewater %>% spread(key = 'Alts', value = 'Dewater')
#do any EOS fall below 2200 TAF?
EOS <- 2717
eosList <- list()
eosList <- eosList %>% append(
list(total_volume_as = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
eos_aug90 <- eosList$total_volume_as["aug90_cfs"]
eosList <- eosList %>% append(
list(Difference_from_aug90 = (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(eosList)
)
eosList <- eosList %>% append(
list(Resulting_EOS = (EOS - (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000))),
after = length(eosList)
)
if(min(eosList$Resulting_EOS) > 2200){
TDM <- "All proposed scenarios are anticipated to have EOS storage greater than the 2200 TAF threshold and therefore would not be expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
} else {
TDM <- "One or more proposed scenarios are anticipated to have EOS storage below the 2200 TAF threshold and therefore would be expected to contribute to TDM in the subsequent year, though scenarios above the threshold are not expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year"
}
exp <- vector()
pop_temp <- pop_tab %>% rename('Expansion' = 'Expansion Number') %>% filter(Expansion > 1, !grepl('Expected', Name))
for(i in 1:nrow(pop_temp)){
temp <- pop_temp[i,'Expansion']
temp <- paste0('Winter-run Percent Lost (expansion of ', temp,')')
exp[i] <- temp
}
Metric <- c("Avg Sept Flow (cfs)", "Avg Oct Flow (cfs)", "Sept-Feb Total Volume (TAF)", "Aug-Sept Total Volume (TAF)", "Anticipated EOS Storage (TAF)", "Winter-run Redds Dewatered", "Winter-run Percent Lost (current count)", "Winter-run Percent Lost (mean expansion of 2)", "Winter-run Redds Dewatered (250 cfs buffer)", "Winter-run Percent Lost (250 cfs buffer)")
table <- data.frame(Metric)
tableList <- list()
#creating the table using the row names
table <- data.frame(Metric)
#creating a list to store all summary statistics below
tableList <- list()
#summary statistics for flow which are stored in tableList
tableList <- append(tableList, list(avg_sept_flow = colMeans(septKesFlow[,-1], na.rm = TRUE)), after = length(tableList))
tableList <- append(tableList, list(avg_oct_flow = colMeans(octKesFlow[,-1], na.rm = TRUE)), after = length(tableList))
tableList <- tableList %>% append(
list(total_volume_sf = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-09-01') & date < paste0(yr+1,'-03-01'))[, -1])*1.983/1000)),
after = length(tableList)
)
tableList <- tableList %>% append(
list(total_volume_as = (colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000)),
after = length(tableList)
)
tableList <- tableList %>% append(
list(Resulting_EOS = (EOS - (eos_aug90 - colSums(filter(kesFlowReal2, date >= paste0(yr,'-08-01') & date < paste0(yr,'-10-01'))[, -1])*1.983/1000))),
after = length(tableList)
)
#summary statistics for redd dewatering
tableList <- tableList %>% append(
list(wr_dewatered = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE))),
after = length(tableList)
)
tableList <- tableList %>% append(
list(wr_pct_lost = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE)/reddCount)*100),
after = length(tableList)
)
#summary statistics for redd dewatering with expansion factors
tableList <- tableList %>% append(
list(wr_pct_lost_300 = (colSums(filter(dewater, Buffer == 'NO')[, -1:-2], na.rm = TRUE)/(reddCount*2))*100),
after = length(tableList)
)
#summary statsitics for redd dewatering with flow buffer
tableList <- tableList %>% append(
list(wr_dewatered_250 = (colSums(filter(dewater, Buffer == 'YES')[, -1:-2], na.rm = TRUE))),
after = length(tableList)
)
tableList <- tableList %>% append(
list(wr_pct_lost_250 = (colSums(filter(dewater, Buffer == 'YES')[, -1:-2], na.rm = TRUE)/reddCount)*100),
after = length(tableList)
)
#binding summary statistics into one table
temp_table <- bind_rows(tableList)
#binding to original table with row names
table <- bind_cols(Metric, temp_table) %>% rename('Metric' = 1)
#adding fall-run dewatering to table
table <- rbind(table, setNames(table2, names(table))) %>%
mutate_at(c(2:ncol(table)), as.numeric)
# Separate the data into two parts: the first 5 rows and the remaining rows
table[,2:ncol(table)] <- round(table[,2:ncol(table)], 2)
colnames(table) <- gsub("_cfs$", "", colnames(table))
View(table)
test2 <- table %>%
rowwise() %>%
mutate(across(-Metric),
~ifelse(Metric %in% c("Avg Sept Flow (cfs)", "Avg Oct Flow (cfs)", "Sept-Feb Total Volume (TAF)",
"Aug-Sept Total Volume (TAF)", "Anticipated EOS Storage (TAF)", "Winter-run Redds Dewatered"),
round(.x, digits = 0),
round(.x, digits = 2))) %>%
ungroup()
test2 <- table %>%
rowwise() %>%
mutate(across(-Metric,
~ ifelse(Metric %in% c("Avg Sept Flow (cfs)", "Avg Oct Flow (cfs)",
"Sept-Feb Total Volume (TAF)", "Aug-Sept Total Volume (TAF)",
"Anticipated EOS Storage (TAF)", "Winter-run Redds Dewatered"),
round(.x, digits = 0),
round(.x, digits = 2)))) %>%
ungroup()
View(test2)
View(table)
table
table_rounded <- table %>%
mutate(across(-Metric,
~ ifelse(row_number() <= 6, round(.x, digits = 0), round(.x, digits = 2))))
View(table_rounded)
table_rounded
View(table_rounded)
table_rounded <- table %>%
mutate(across(-Metric,
~ ifelse(row_number() <= 6, as.integer(round(.x, digits = 0)), round(.x, digits = 2))))
# View the result
table_rounded
table_rounded
worksheetSD <- read_xlsx(paste0('External_data/FlowScen/',MaxFile), sheet = "Scenario Description",range="A1:A1000",col_names=F,col_types="text")
# remove extraneous lines, keeping lines with "=" in it
keep=apply(worksheetSD,2,function(x.in) str_detect(x.in,"="))
worksheetSD=worksheetSD[keep,]
worksheetSD=worksheetSD[!is.na(worksheetSD[,1]),]
# split the Alts from the descriptions
num.in = dim(worksheetSD)[1]
scenarioDesc=data.frame(matrix(nrow=num.in,ncol=2))
colnames(scenarioDesc)=c("Scenario","Descripion")
# loop through dataframe, split original dataframe column 1 on literal "=" characters and trim leading and trailing space, create new dataframe with 2 columns "Scenario" and "Description"
# populates scenarioDesc dataframe
for(i in 1:num.in){
scenarioDesc[i,]=str_trim(str_split(worksheetSD[i,1],"=")[[1]])
}
scenarioDesc <- scenarioDesc %>%
mutate(Key = gsub("[^[:alnum:]]+", "", Scenario)) %>%
mutate(Key = tolower(Key)) %>%
filter(Key %in% scen)
#use scenarios defined in first chunk of code to filter the scenarioDesc dataframe
#filter based on scenario name
#scenarioDesc <- scenarioDesc %>%
#filter(grepl(paste(toupper(scenarios2), collapse ='|'), toupper(Scenario)))
if (knitr::is_html_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.')
} else if (knitr::is_latex_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
column_spec(1, width = "3cm") %>%
column_spec(2, width = "13cm")
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(scenarioDesc) %>%
flextable::set_caption(caption = 'Table 3. Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
flextable::width(1, width = 1.5, unit = "in") %>%
flextable::width(2, width = 5, unit = "in")
}
View(scenarioDesc)
worksheetSD <- read_xlsx(paste0('External_data/FlowScen/',MaxFile), sheet = "Scenario Description",range="A1:A1000",col_names=F,col_types="text")
# remove extraneous lines, keeping lines with "=" in it
keep=apply(worksheetSD,2,function(x.in) str_detect(x.in,"="))
worksheetSD=worksheetSD[keep,]
worksheetSD=worksheetSD[!is.na(worksheetSD[,1]),]
# split the Alts from the descriptions
num.in = dim(worksheetSD)[1]
scenarioDesc=data.frame(matrix(nrow=num.in,ncol=2))
colnames(scenarioDesc)=c("Scenario","Descripion")
# loop through dataframe, split original dataframe column 1 on literal "=" characters and trim leading and trailing space, create new dataframe with 2 columns "Scenario" and "Description"
# populates scenarioDesc dataframe
for(i in 1:num.in){
scenarioDesc[i,]=str_trim(str_split(worksheetSD[i,1],"=")[[1]])
}
scenarioDesc <- scenarioDesc %>%
mutate(Key = gsub("[^[:alnum:]]+", "", Scenario)) %>%
mutate(Key = tolower(Key)) %>%
filter(Key %in% scen) %>%
mutate(paste0(Scenario,' (',key,')'))
worksheetSD <- read_xlsx(paste0('External_data/FlowScen/',MaxFile), sheet = "Scenario Description",range="A1:A1000",col_names=F,col_types="text")
# remove extraneous lines, keeping lines with "=" in it
keep=apply(worksheetSD,2,function(x.in) str_detect(x.in,"="))
worksheetSD=worksheetSD[keep,]
worksheetSD=worksheetSD[!is.na(worksheetSD[,1]),]
# split the Alts from the descriptions
num.in = dim(worksheetSD)[1]
scenarioDesc=data.frame(matrix(nrow=num.in,ncol=2))
colnames(scenarioDesc)=c("Scenario","Descripion")
# loop through dataframe, split original dataframe column 1 on literal "=" characters and trim leading and trailing space, create new dataframe with 2 columns "Scenario" and "Description"
# populates scenarioDesc dataframe
for(i in 1:num.in){
scenarioDesc[i,]=str_trim(str_split(worksheetSD[i,1],"=")[[1]])
}
scenarioDesc <- scenarioDesc %>%
mutate(Key = gsub("[^[:alnum:]]+", "", Scenario)) %>%
mutate(Key = tolower(Key)) %>%
filter(Key %in% scen) %>%
mutate(paste0(Scenario,' (',Key,')'))
#use scenarios defined in first chunk of code to filter the scenarioDesc dataframe
#filter based on scenario name
#scenarioDesc <- scenarioDesc %>%
#filter(grepl(paste(toupper(scenarios2), collapse ='|'), toupper(Scenario)))
if (knitr::is_html_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.')
} else if (knitr::is_latex_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
column_spec(1, width = "3cm") %>%
column_spec(2, width = "13cm")
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(scenarioDesc) %>%
flextable::set_caption(caption = 'Table 3. Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
flextable::width(1, width = 1.5, unit = "in") %>%
flextable::width(2, width = 5, unit = "in")
}
View(scenarioDesc)
worksheetSD <- read_xlsx(paste0('External_data/FlowScen/',MaxFile), sheet = "Scenario Description",range="A1:A1000",col_names=F,col_types="text")
# remove extraneous lines, keeping lines with "=" in it
keep=apply(worksheetSD,2,function(x.in) str_detect(x.in,"="))
worksheetSD=worksheetSD[keep,]
worksheetSD=worksheetSD[!is.na(worksheetSD[,1]),]
# split the Alts from the descriptions
num.in = dim(worksheetSD)[1]
scenarioDesc=data.frame(matrix(nrow=num.in,ncol=2))
colnames(scenarioDesc)=c("Scenario","Descripion")
# loop through dataframe, split original dataframe column 1 on literal "=" characters and trim leading and trailing space, create new dataframe with 2 columns "Scenario" and "Description"
# populates scenarioDesc dataframe
for(i in 1:num.in){
scenarioDesc[i,]=str_trim(str_split(worksheetSD[i,1],"=")[[1]])
}
scenarioDesc <- scenarioDesc %>%
mutate(Key = gsub("[^[:alnum:]]+", "", Scenario)) %>%
mutate(Key = tolower(Key)) %>%
filter(Key %in% scen) %>%
mutate(Scenario = paste0(Scenario,' (',Key,')'))
#use scenarios defined in first chunk of code to filter the scenarioDesc dataframe
#filter based on scenario name
#scenarioDesc <- scenarioDesc %>%
#filter(grepl(paste(toupper(scenarios2), collapse ='|'), toupper(Scenario)))
if (knitr::is_html_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.')
} else if (knitr::is_latex_output()) {
knitr::kable(scenarioDesc,
caption = 'Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
column_spec(1, width = "3cm") %>%
column_spec(2, width = "13cm")
} else if (knitr::pandoc_to("docx")) {
flextable::flextable(scenarioDesc) %>%
flextable::set_caption(caption = 'Table 3. Description of scenarios being considered and compared by the Upper Sacramento Scheduling Team.') %>%
flextable::width(1, width = 1.5, unit = "in") %>%
flextable::width(2, width = 5, unit = "in")
}
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files('External_data/ShallowRedds/ReddCount/',
pattern = "xlsx$") #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE))
library(tinytex)
library(data.table)
library(plyr)
library(ggplot2)
library(tidyverse)
library(readxl)
library(zoo)
library(kableExtra)
library(janitor)
library(lubridate)
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files('External_data/ShallowRedds/ReddCount/',
pattern = "xlsx$") #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE))
View(sheetCount)
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE)) %>%
pull(name = 'Reporting')
sheetCount <- data.frame(excel_sheets(paste0('External_data/ShallowRedds/ReddCount/',
MaxCountFile))) %>% #read in most recent excel WITH count data
rename('name' = 1) %>%
filter(grepl('REPORTING', name, ignore.case = TRUE)) %>%
pull(name)
Count <- read_excel(paste0('External_data/ShallowRedds/ReddCount/',MaxCountFile),
sheet = sheetCount)
