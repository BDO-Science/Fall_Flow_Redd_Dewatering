round_to_nearest <- function(x, basis_vector) {
nearest_value <- basis_vector[which.min(abs(basis_vector - x))]
return(nearest_value)
}
#transform kesFlowReal dataframe for model
redd_model <- scens_with_rt_flows %>%
pivot_longer(names_to = 'Scenarios', values_to = 'Spawn_Flows', -1) %>%
mutate(Boards = if_else(Date < as.Date(paste0(yr,'-11-01')), 'in', 'out')) %>%
mutate(Spawn_Flows = as.numeric(Spawn_Flows)) %>%
left_join(spawn, by = c('Date')) %>%
filter(!is.na(run)) %>%
mutate(Spawn_Flows = zoo::na.approx(Spawn_Flows), EmergDate = Date + incubDays) %>%
mutate(Dewater = sapply(EmergDate, function(edate) {
if (!is.na(edate)) {
min(Spawn_Flows[Date <= edate & Date >= Date], na.rm = TRUE)
} else {
NA
}
}))
redd_model_final <- redd_model %>%
mutate(GardSpawn = sapply(redd_model$Spawn_Flows, round_to_nearest, fall_lookup$GardSpawn)) %>%
mutate(GardDewater = sapply(redd_model$Dewater, round_to_nearest, fall_lookup$GardDewater)) %>%
left_join(fall_lookup, by = c('GardDewater', 'GardSpawn', 'Boards')) %>%
mutate(Prop_dewater = if_else(is.na(Prop_dewater), 0, Prop_dewater)) %>%
mutate(TotalDewater = prop * Prop_dewater)
fall_dewater_summary <- redd_model_final %>%
group_by(Scenarios, year) %>% #summarize total dewatering by Scenario
summarize(Redds_lost = round((sum(TotalDewater)*100), 1)) %>%
pivot_wider(names_from = 'Scenarios', values_from = 'Redds_lost') %>%
filter(year > 2013)
fall_dewater_mean <- fall_dewater_summary %>%
summarize(across(-1, ~mean(.x, na.rm = TRUE))) %>%
mutate(year = "Mean", .before = 1)
all_dewater_table <- fall_dewater_summary %>%
datawizard::data_transpose(colnames = TRUE) %>%
rownames_to_column(var = 'Scenario')
fall_dewater_for_table <- fall_dewater_mean %>%
select(-1) %>%
mutate(across(everything(), ~ round(.x, 1)))
####various optional graphs
# min_year <- min(as.numeric(fall_dewater_summary$year), na.rm = TRUE)
#
# spawn_graph_2 <- ggplot() +
#   geom_boxplot(spawn, mapping = aes(x = factor(year), y = Date, fill = factor(year)),
#                color = 'black') +
#   scale_fill_viridis_d() +
#   labs(x = 'Spawn Year') +
#   coord_flip() +
#   theme_bw() +
#   theme(legend.position = 'none')
# spawn_graph_2
#
# fall_dewater_summary_test <- fall_dewater_summary %>%
#   mutate(C1 = B1, D1 = B1, E1 = B1, F1 = B1, G1 = B1)
# dewater_graph <- fall_dewater_summary_test %>%
#   pivot_longer(names_to = 'Scenarios', values_to = 'dewater', -1) %>%
#   ggplot(aes(x = Scenarios, y = dewater, fill = Scenarios)) +
#   scale_fill_viridis_d(option = 'turbo') +
#   #geom_tile(width = 0.9, height = 0.9, color = 'black') +
#   #geom_label(aes(label = dewater), fill = 'white', size = 3) +
#   geom_col(color = 'black') +
#   facet_wrap(~year, ncol = 1) +
#   scale_y_continuous(position = 'right') +
#   labs(y = 'Redds Dewatered (%)') +
#   #coord_flip() +
#   theme_bw() +
#   theme(legend.position = 'none',
#         strip.background = element_blank(),
#         strip.text = element_blank())
# dewater_graph
#
# final_graph <- (spawn_graph_2|dewater_graph) + plot_layout(widths = c(4.5,1.5))
# final_graph
# #ggsave(plot = final_graph, file = 'test_graph.png', height = 9, width = 10)
# spawning_cum_half <- spawn %>%
#   mutate(cum_round = round(cumul_prop, 1)) %>%
#   filter(cum_round == 0.5) %>%
#   group_by(year) %>%
#   slice_head(n = 1)
# spawn_graph <-  ggplot() +
#   geom_line(filter(spawn, year >= min_year),
#             mapping = aes(x = Date, y = cumul_prop),
#             color = 'steelblue3',
#             linewidth = 1) +
#   geom_point(filter(spawning_cum_half, year >= min_year),
#mapping = aes(x = Date, y = 0.50),
#size = 2,
#shape = 8,
#stroke = 2) +
#geom_text(filter(spawning_cum_half, year >= min_year),
#mapping = aes(x = Date-15, y = 0.50+0.12, label = format(Date, '%b %d'))) +
#labs(y = 'Cumulative Spawning Proportion') +
#facet_wrap(~year, ncol = 2) +
#theme_bw()
#spawn_graph
##########################
#expansion factor
##########################
pop_tab <- data.frame(Expansion = seq(1,3.5,0.5)) %>%
mutate(Redds = round(reddCount*Expansion, 0),
"Dewatering Threshold (1%)" = round(Redds*0.01,0)) %>%
rename("Expansion Factor" = Expansion,
"Total Redds" = Redds)
######################
#winter-run dewatering
######################
wr_min_flow <- data.frame()
redds_ok <- redds %>%
filter(status == 'OK')
redds_total <- nrow(redds)
redds_dewatered <- nrow(subset(redds, grepl("dewater", status, ignore.case = TRUE)))
redds_emerged <- nrow(subset(redds, redds$status == "EMERGED"))
for(i in 1:nrow(redds_ok)) {
temp <- filter(scens_with_rt_flows, Date <= redds$emergence_date[i]
& Date >= redds$date_established[i]) %>%
summarize(across(-1, min))
wr_min_flow <- bind_rows(wr_min_flow, temp)
}
redds2 <- bind_cols(redds_ok, wr_min_flow) %>%
mutate(dewater_flow_250_buffer = dewater_flow + 250) %>%
pivot_longer(names_to = 'Scenarios', values_to = 'min_flow', 6:(ncol(.)-1)) %>%
mutate(dewater = if_else(dewater_flow > min_flow, 1, 0),
dewater_250_buffer = if_else(dewater_flow_250_buffer > min_flow, 1, 0))
wr_dewater <- redds2 %>% group_by(Scenarios) %>%
summarize(dewater = sum(dewater) + redds_dewatered,
dewater_250_buffer = sum(dewater_250_buffer) + redds_dewatered) %>%
ungroup() %>%
mutate(dewater_perc = round((dewater/reddCount)*100,1),
dewater_perc_exp = round((dewater/(reddCount*exp_fac)*100),1),
dewater_perc_250_buffer = round((dewater_250_buffer/(reddCount)*100),1)) %>%
select(1,2,4,5,3,6) %>%
datawizard::data_transpose(colnames = TRUE,
rownames = NULL)
rownames(wr_dewater) <- NULL
##########################
#volume and flow summaries
##########################
avg_flow_sep_oct <- scens_with_rt_flows %>%
mutate(month = month(Date)) %>%
filter(month %in% c(9,10)) %>%
group_by(month) %>%
summarize(across(-1,mean)) %>%
select(-1)
sep_feb_volume <- scens_with_rt_flows %>%
filter(Date > paste0(yr,'-08-31')) %>%
summarize(across(-1, ~ sum(.x) * 1.983 / 1000)) %>%
mutate(across(everything(), ~ round(.x, 0)))
aug_sep_volume <- scens_with_rt_flows %>%
filter(Date <= paste0(yr,'-09-30')) %>%
summarize(across(-1, ~ sum(.x) * 1.983 / 1000)) %>%
mutate(across(everything(), ~ round(.x, 0)))
##########################
#creating summary table
##########################
#create column of measures
Metric <- data.frame(Measure = c("Avg Sept Flow (cfs)", "Avg Oct Flow (cfs)",
"Sept-Feb Total Volume (TAF)", "Aug-Sept Total Volume (TAF)", "Winter-run Redds Dewatered",
"Winter-run % Lost (expansion factor = 1)", paste0("Winter-run % Lost (expansion factor = ",exp_fac,")"),
"Winter-run Redds Dewatered (250 cfs buffer)", "Winter-run % Lost (250 cfs buffer)",
"Fall-run % Redds Dewatered"))
summary_table <- bind_rows(avg_flow_sep_oct, sep_feb_volume, aug_sep_volume,
wr_dewater, fall_dewater_for_table) %>%
bind_cols(Metric) %>%
select(ncol(.), 1:ncol(.))
summary_table_flow <- slice(summary_table, 1:4) %>%
rename('Volume Measures' = 'Measure')
summary_table_counts <- slice(summary_table, 5,8) %>%
rename('Dewatering Count Measures' = 'Measure')
summary_table_percent <- slice(summary_table, 6,7,9,10) %>%
rename('Dewatering % Measures' = 'Measure')
##########################
#dewatering graph
##########################
ymin <- plyr::round_any(min(redds$dewater_flow), 1000, f = floor)
ymax <- plyr::round_any(max(scens_with_rt_flows[2:3])+400, 500, f = ceiling)
todays_date <- Sys.Date()
mid <- as.Date(paste0(yr,'-08-01')) + floor((todays_date - as.Date(paste0(yr,'-08-01')))/2)
redds_graph <- redds %>% group_by(emergence_date, status, dewater_flow) %>%
summarize(count = n()) %>%
ungroup() %>%
mutate(status = case_when(grepl('dewater', status, ignore.case = TRUE) ~ 'DEWATER',
grepl('ok', status, ignore.case = TRUE) ~ 'OK',
grepl('emerge', status, ignore.case = TRUE) ~ 'EMERGED')) %>%
mutate(status = factor(status,
levels = c('OK', 'EMERGED', 'DEWATER'),
labels = c('Re', 'Em', 'De')))
flows <- scens_with_rt_flows %>%
pivot_longer(names_to = 'Alts', values_to = 'Flow', -1) %>%
filter(Date >= max(rt_flows$date))
redd_graph <- ggplot() + geom_line(flows, mapping = aes(x = Date, y = Flow, color = Alts), linewidth = 0.75) +
geom_line(rt_flows, mapping = aes(x = date, y = flow, linetype = location), linewidth = 0.75) +
geom_point(redds_graph, mapping = aes(x = emergence_date, y = dewater_flow, fill = status),
shape = 21, size = 6, color = 'black',
) +
geom_text(redds_graph, mapping = aes(x = emergence_date, y = dewater_flow, label = count),
color = 'black') +
ylim(ymin, ymax+200) +
xlim(min(as.Date(paste0(yr,'-08-01'))), (max(redds$emergence_date) + 5)) +
labs(x = 'Date', y = 'Flow (cfs)', fill = 'Redd Status', linetype = '') +
theme_bw() +
theme(legend.position = 'bottom',
legend.text = element_text(size = 12),
axis.text = element_text(size = 10),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.key.size = unit(0.3, 'cm')) +
scale_fill_manual(values = c(Re = 'lightgrey', Em = 'steelblue3', De = 'darkorange')) +
annotate(geom = 'rect', xmin = as.Date(paste0(yr,'-08-01')), xmax = max(rt_flows$date),
ymin = 3000, ymax = max(rt_flows$flow) + 100, fill = 'darkgrey', color = 'black', alpha = 0.2, linetype = 'dotted') +
annotate(geom = 'text', x = (mid + 0.5), y = max(rt_flows$flow) + 350, size = 3.5,
fontface = 'italic', label = 'Actual Flows')
redd_graph
##########################
#EOS analysis
##########################
projected_90_cost <- (sum(forecast_90_flows$flow) * 1.983) / 1000
eos_scen <- aug_sep_volume %>%
pivot_longer(names_to = 'Scenario', values_to = 'Vol', 1:ncol(aug_sep_volume)) %>%
mutate(eos = eosStorage - (Vol-projected_90_cost))
View(eos_scen)
View(aug_sep_volume)
View(forecast_90_flows)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2)
View(forecast_90_flows)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date))
View(kes_flow_bind)
View(rt_flows)
View(kes)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date)) %>%
bind_rows(select(filter(rt_flows, location = 'KES'), -location), Date, flow)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date)) %>%
bind_rows(select(filter(rt_flows, location == 'KES'), -location), Date, flow)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date)) %>%
bind_rows(select(filter(rt_flows, location == 'KES'), -location), Date)
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date)) %>%
bind_rows(select(filter(rt_flows, location == 'KES'), -location, Date = date, flow))
projected_90_cost <- (sum(forecast_90_flows$flow) * 1.983) / 1000
eos_scen <- aug_sep_volume %>%
pivot_longer(names_to = 'Scenario', values_to = 'Vol', 1:ncol(aug_sep_volume)) %>%
mutate(eos = eosStorage - (Vol-projected_90_cost))
roundeosStorage <- round(eosStorage, 100)
roundeosStorage <- round(eosStorage, ceiling)
roundeosStorage <- floor(eosStorage)
roundeosStorage <- plyr::round_any(eosStorage, 100)
roundeosStorage <- plyr::round_any(eosStorage, 100)/1000
carryover_safe <- paste('All proposed scenarios are anticipated to have EOS storage greater than the 2,200 TAF threshold and therefore would not be',
'expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year.',
'Scenarios focused on avoiding dewatering of winter-run redds have higher releases',
'through early November which is not factored into this performance indicator.')
eos_scen_paste <- eos_scen %>%
filter(eos <= 2200) %>%
pull(scenario)
eos_scen <- aug_sep_volume %>%
pivot_longer(names_to = 'Scenario', values_to = 'Vol', 1:ncol(aug_sep_volume)) %>%
mutate(eos = eosStorage - (Vol-projected_90_cost))
View(eos_scen)
eos_scen_paste <- eos_scen %>%
filter(eos <= 2200) %>%
pull(Scenario)
carryover_bad <- paste('scenarios',eos_scen_paste, 'are anticipated to have EOS storage less than the 2,200 TAF threshold and therefore may',
'contribute to TDM impacts to winter-run chinook salmon in the subsequent year.',
'Scenarios focused on avoiding dewatering of winter-run redds have higher releases',
'through early November which is not factored into this performance indicator.')
carryover_bad
eos_scen_filter <- eos_scen %>%
filter(eos <= 2200) %>%
pull(Scenario)
eos_scen_paste <- paste(eos_scen_filter, collapse = ", ")
carryover_safe <- paste('All proposed scenarios are anticipated to have EOS storage greater than the 2,200 TAF threshold and therefore would not be',
'expected to contribute to TDM impacts to winter-run chinook salmon in the subsequent year.',
'Scenarios focused on avoiding dewatering of winter-run redds have higher releases',
'through early November which is not factored into this performance indicator.')
carryover_bad <- paste('scenarios',eos_scen_paste, 'are anticipated to have EOS storage less than the 2,200 TAF threshold and therefore may',
'contribute to TDM impacts to winter-run chinook salmon in the subsequent year.',
'Scenarios focused on avoiding dewatering of winter-run redds have higher releases',
'through early November which is not factored into this performance indicator.')
carryover_text <- if(length(eos_scen_filter) == 0) {
print(carryover_safe)
} else {
print(carryover_bad)
}
View(aug_sep_volume)
View(aug_sep_volume)
View(avg_flow_sep_oct)
avg_flow_sep_oct <- scens_with_rt_flows %>%
mutate(month = month(Date)) %>%
filter(month %in% c(9,10)) %>%
group_by(month) %>%
summarize(across(-1,mean)) %>%
select(-1) %>%
mutate(across(everything(), ~ round(.x, 0)))
library(tidyverse)
library(janitor)
library(here)
library(readxl)
project <- here::here() #pointing to working directory
#user defined values
wy <- 2025
exp_fac <- 2.04
yr <- year(Sys.Date())
##############################
#Reading in shallow redd files
##############################
#######Read in redd data from shallow winter redd monitoring
redd_files <- list.files(here::here(project, 'input_data/shallow_redds/'), pattern = "\\.xlsx$", full.names = TRUE) #list all excel files
MaxReddFile <- max(redd_files) #reads the latest redd excel file
reddsheet <- tibble(sheet = excel_sheets(MaxReddFile)) %>%
filter(grepl('shallow',sheet,ignore.case = TRUE)) %>%
filter(!grepl('sacpas',sheet,ignore.case = TRUE)) %>%
pull()
redds <- read_excel(MaxReddFile,  sheet = reddsheet, #read in shallow redd file and clean up.
range = cell_cols(c('A:I'))) %>%
na.omit() %>%
select(redd_id = 2, date_established = 3,emergence_date = 4, status = 6, dewater_flow = 9) %>%
mutate_at(2:3, as.Date) %>%#minor cleaning
mutate(dewater_flow = as.numeric(str_extract(dewater_flow, "\\d+\\.*\\d*")))
#######################
#reading in scenarios
#######################
scen_files <- list.files(here::here(project, 'input_data/flow_scen/'), full.names = TRUE, pattern = "xlsx$")
MaxScenFile <- max(scen_files)
flowsheets <- excel_sheets(MaxScenFile)
flowsheet <- grep("Alternatives", flowsheets, ignore.case = TRUE, value = TRUE) #for pulling in flow alternatives
scensheet <- grep("Desired", ignore.case = TRUE, flowsheets, value = TRUE) #for pulling in desired scenarios sheet
scendesc <- grep("Description", ignore.case = TRUE, flowsheets, value = TRUE)
#pull in desired scenarios for filtering
scen_filter <- read_excel(MaxScenFile,
sheet = scensheet, col_names = TRUE) %>%
filter(Use == 'Y') %>%
pull(Scenario)
#pull in flow alternatives
scen_flow_import <- read_excel(MaxScenFile,
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
mutate(Date = as.Date(as.numeric(Date), origin = "1899-12-30")) %>%
select(-Actual) %>%
pivot_longer(names_to = 'scenarios', values_to = 'flow', -1) %>%
filter(scenarios %in% scen_filter,
!is.na(Date))
#pull in scenario description
scen_descriptions <- read_excel(MaxScenFile,
sheet = scendesc, skip = 6) %>%
separate(1, into = c('Scenario', 'Description'), sep = ':') %>%
filter(Scenario %in% scen_filter)
eosStorage <- read_excel(MaxScenFile,
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
filter(grepl('end of september', Date, ignore.case = TRUE)) %>%
pivot_longer(-Date, names_to = "column", values_to = "value") %>%
group_by() %>%
summarize(min(value, na.rm = TRUE)) %>%
pull()
###########################################
#read in Redd Count data and date from
#most recent file with that info
#different folder than standard redd files
###########################################
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files(here::here(project,'input_data/shallow_redds/ReddCount/'),
pattern = "xlsx$", full.names = TRUE) #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- tibble(sheet = excel_sheets(MaxCountFile)) %>% #read in most recent excel WITH count data
filter(grepl('REPORTING', sheet, ignore.case = TRUE)) %>%
pull()
library(tidyverse)
library(janitor)
library(here)
library(readxl)
project <- here::here() #pointing to working directory
#user defined values
wy <- 2025
exp_fac <- 2.04
yr <- year(Sys.Date())
##############################
#Reading in shallow redd files
##############################
#######Read in redd data from shallow winter redd monitoring
redd_files <- list.files(here::here(project, 'input_data/shallow_redds/'), pattern = "\\.xlsx$", full.names = TRUE) #list all excel files
MaxReddFile <- max(redd_files) #reads the latest redd excel file
reddsheet <- tibble(sheet = excel_sheets(MaxReddFile)) %>%
filter(grepl('shallow',sheet,ignore.case = TRUE)) %>%
filter(!grepl('sacpas',sheet,ignore.case = TRUE)) %>%
pull()
redds <- read_excel(MaxReddFile,  sheet = reddsheet, #read in shallow redd file and clean up.
range = cell_cols(c('A:I'))) %>%
na.omit() %>%
select(redd_id = 2, date_established = 3,emergence_date = 4, status = 6, dewater_flow = 9) %>%
mutate_at(2:3, as.Date) %>%#minor cleaning
mutate(dewater_flow = as.numeric(str_extract(dewater_flow, "\\d+\\.*\\d*")))
#######################
#reading in scenarios
#######################
scen_files <- list.files(here::here(project, 'input_data/flow_scen/'), full.names = TRUE, pattern = "xlsx$")
MaxScenFile <- max(scen_files)
flowsheets <- excel_sheets(MaxScenFile)
flowsheet <- grep("Alternatives", flowsheets, ignore.case = TRUE, value = TRUE) #for pulling in flow alternatives
scensheet <- grep("Desired", ignore.case = TRUE, flowsheets, value = TRUE) #for pulling in desired scenarios sheet
scendesc <- grep("Description", ignore.case = TRUE, flowsheets, value = TRUE)
#pull in desired scenarios for filtering
scen_filter <- read_excel(MaxScenFile,
sheet = scensheet, col_names = TRUE) %>%
filter(Use == 'Y') %>%
pull(Scenario)
#pull in flow alternatives
scen_flow_import <- read_excel(MaxScenFile,
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
mutate(Date = as.Date(as.numeric(Date), origin = "1899-12-30")) %>%
select(-Actual) %>%
pivot_longer(names_to = 'scenarios', values_to = 'flow', -1) %>%
filter(scenarios %in% scen_filter,
!is.na(Date))
#pull in scenario description
scen_descriptions <- read_excel(MaxScenFile,
sheet = scendesc, skip = 6) %>%
separate(1, into = c('Scenario', 'Description'), sep = ':') %>%
filter(Scenario %in% scen_filter)
eosStorage <- read_excel(MaxScenFile,
sheet = flowsheet, skip = 1, col_names = TRUE) %>%
filter(grepl('end of september', Date, ignore.case = TRUE)) %>%
pivot_longer(-Date, names_to = "column", values_to = "value") %>%
group_by() %>%
summarize(min(value, na.rm = TRUE)) %>%
pull()
###########################################
#read in Redd Count data and date from
#most recent file with that info
#different folder than standard redd files
###########################################
count_pattern <- 'To date, unexpanded redd count' #set pattern for count cell to look for
date_pattern <- 'Through' #set pattern for date cell to look for
CountFiles <- list.files(here::here(project,'input_data/shallow_redds/ReddCount/'),
pattern = "xlsx$", full.names = TRUE) #list files with reporting tab in them
MaxCountFile <- max(CountFiles) #single out the most recent file
sheetCount <- tibble(sheet = excel_sheets(MaxCountFile)) %>% #read in most recent excel WITH count data
filter(grepl('REPORTING', sheet, ignore.case = TRUE)) %>%
pull()
#for Count data
Count <- read_excel(MaxCountFile,
sheet = sheetCount) #pull in sheet with count data
reddCountquery <- round(as.numeric(Count[[(which(Count[, 2] == 'To date, unexpanded redd count') + 1), 2]]),0) #isolate count
countDatequery <- as.Date(as.numeric(Count[[(which(Count[, 1] == 'Through') + 1), 1]]),
origin = "1899-12-30")
countDate <- if (countDatequery == as.Date('2025-07-23')) {
format(as.Date('2025-08-13'), "%B %d, %Y")
} else {
format(countDatequery, "%B %d, %Y")
}
reddCount <- if(reddCountquery == 901) {
2206
} else {
reddCountquery
}
updatedReddInfoDate <- read_excel(MaxReddFile,
sheet = grep('sacpas', excel_sheets(MaxReddFile),
ignore.case = TRUE)) %>%
summarize(max(measurement_date)) %>% pull()
#########################################
#pull in flow data from kwk and kes
#merge real-time flow data with scenarios
#########################################
#kwk <- cdec_query('KWK', '41', 'D', paste0(wy-1,'-08-01'), Sys.Date())
#kes <- cdec_query('KES', '23', 'D', paste0(wy-1,'-08-01'), Sys.Date())
kwk_url <- paste0("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?sc=1&mgconfig=river&outputFormat=csv&hafilter=All&year%5B%5D="
,wy,"&loc%5B%5D=KWK&data%5B%5D=Flow&tempUnit=F&startdate=1%2F1&enddate=12%2F31&avgyear=0&consolidate=1&grid=1&y1min=&y1max=&y2min=&y2max=&size=large")
kes_url <- paste0("https://www.cbr.washington.edu/sacramento/data/php/rpt/mg.php?sc=1&mgconfig=river&outputFormat=csv&hafilter=All&year%5B%5D="
,wy,"&loc%5B%5D=KES&data%5B%5D=ReservoirOutflow&tempUnit=F&startdate=1%2F1&enddate=12%2F31&avgyear=0&consolidate=1&grid=1&y1min=&y1max=&y2min=&y2max=&size=large")
kwk <- read_csv(kwk_url) %>% clean_names() %>% #importing kwk data from SacPAS
mutate(location = 'KWK') %>%
select(date = 1, 3,flow = 2)
kes <- read_csv(kes_url) %>% clean_names() %>% #importing kes data from SacPAS
mutate(location = 'KES') %>%
select(date = 1, 3,flow = 2)
rt_flows <- bind_rows(kwk,kes) %>%
mutate(date = mdy(paste0(date,'/',wy))) %>%
filter(!is.na(date),
!is.na(flow)) %>%
filter(date <= Sys.Date()) %>%
filter(date >= as.Date('2025-08-01'))
kes_flow_bind <- rt_flows %>%
filter(location == 'KES') %>% #filter for only KES data
select(-2) %>%
crossing(scenarios = scen_filter) %>% #expands real-time flow data to all desired scenarios
select(Date = 1,3,2)
scens_with_rt_flows <- scen_flow_import %>%
filter(Date > max(kes_flow_bind$Date)) %>% #filter out scenario data by max real-time date
bind_rows(kes_flow_bind) %>% #bind realtime flows
pivot_wider(names_from = 'scenarios', values_from = 'flow')
#########################################
#pull in 90% exceendance flows
#merge with real-time flow data
#########################################
forecast_90_flows <- read_csv(here::here(project, 'input_data/flow_scen/aug_90.csv')) %>%
mutate(Date = mdy(date)) %>%
select(3, 2) %>%
filter(Date > max(kes_flow_bind$Date)) %>%
bind_rows(select(filter(rt_flows, location == 'KES'), -location, Date = date, flow))
